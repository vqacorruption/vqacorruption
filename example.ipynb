{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install requirements\n",
        "\n",
        "Install requirements.txt from the repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAgngiQ8__Hf"
      },
      "source": [
        "# Starting Corruption\n",
        "Define all the parameter of the config file related to path, dataset, corruption, layout analysis and model. \n",
        "\n",
        "## Short explanation of each field:\n",
        "### Paths:\n",
        "- base_path: The root directory for relative paths.\n",
        "- augmented_dataset: Path to the JSON file containing the augmented dataset.\n",
        "- output_corrupted: Destination for the JSON file with all corrupted (unanswerable) questions.\n",
        "- output_corrupted_cleaned: Path for the cleaned version of the corrupted questions.\n",
        "- patch_saving_dir: Directory where patch files (modifications applied during corruption) are saved.\n",
        "- layout_saving_dir: Directory where layout analysis outputs are stored.\n",
        "\n",
        "### Dataset:\n",
        "- type: Indicates the dataset in use, here it's MPDocVQA or DUDE.\n",
        "- split: Specifies the data split (e.g., train) being processed.\n",
        "- dataset_json_path: File path to the original dataset JSON file.\n",
        "\n",
        "### Corruption:\n",
        "- percentage: Determines the proportion (100%) of the data to be corrupted.\n",
        "- complexity: Sets the corruption complexity level (1,2 or 3).\n",
        "- generated_sample_per_complexity_greater_than_1: Number of corrupted samples to generate for complexities higher than 1.\n",
        "- types: A set of boolean flags indicating which types of corruptions to apply (numerical, temporal, entity, location, documentâ€”all enabled).\n",
        "\n",
        "### Layout Analysis:\n",
        "- model: Specifies the layout analysis model to use, which likely helps in understanding or processing document layouts.\n",
        "\n",
        "### Model:\n",
        "- provider: Indicates the model hosting service (huggingface).\n",
        "- name: The primary model used for processing.\n",
        "\n",
        "After defining all the parameter run the main with the config path as parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc28z2CVTiWq"
      },
      "outputs": [],
      "source": [
        "!python /corruption-scripts/corruption/main.py --config /corruption-scripts/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPC2Cr1WBGjX"
      },
      "source": [
        "# Verification step\n",
        "After the corruption process, in the config.json you can edit the parameters related to the verification.\n",
        "\n",
        "### Verification:\n",
        "- provider: The service used for verifying the corrupted outputs (gemini/openai).\n",
        "- api_key: Placeholder for the API key.\n",
        "- verification_input_file: Path to the cleaned corrupted questions that need to be verified.\n",
        "- verification_output_file: Path where the verification results will be saved.\n",
        "- verification_percentage: Indicates that all (100%) of the cleaned corrupted samples should be verified.\n",
        "- model_name: The verification model to use (gemini-2.0-flash).\n",
        "- log_file: File path to save the log output from the verification process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JttLTrBYGutO",
        "outputId": "3a37c899-23d2-4724-f847-e746100874e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AnswerabilityVerifier using device: cuda with provider: gemini\n",
            "Will verify 100% of questions\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739451499.763338   29011 init.cc:232] grpc_wait_for_shutdown_with_timeout() timed out.\n"
          ]
        }
      ],
      "source": [
        "!python /corruption-scripts/verification/answerability_verifier.py --config /corruption-scripts/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-MDCIPLckuU"
      },
      "source": [
        "## JUST FALSE RESULTS\n",
        "Taking unanswerable questions from the verifier file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dzwD6bkctgO",
        "outputId": "683c8bf5-7940-49b7-ef9c-fbc28ddc8272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total questions: 19\n",
            "Questions with false verification: 19\n"
          ]
        }
      ],
      "source": [
        "!python /corruption-scripts/verification/just_false.py --input_file /corruption-scripts/results/MPDocVQA_unanswerable_corrupted_questions_verified.json --output_file /corruption-scripts/results/MPDocVQA_unanswerable_corrupted_questions_verified_just_false.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8OGXoZGCKjP"
      },
      "source": [
        "# VQA Models Testing\n",
        "After the verification process, VQA models can be tested on corrupted questions. \n",
        "\n",
        "You can run each model by passing the VQA_config file path as parameter.\n",
        "\n",
        "## NOTE\n",
        "The results file follows this nomenclature:\n",
        "- results_w#: prompt Explicit\n",
        "- results_w#_ocr: prompt Explicit + OCR\n",
        "- results_w#_unable: prompt None\n",
        "- results_w#_ocr_unable: prompt OCR\n",
        "\n",
        "The parameter batch_size represents the number of pages considered in the evaluation.\n",
        "\n",
        "\"unable_to_respond_aware\" set to false means that the prompt is Explicit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ7CRwKt71b3"
      },
      "source": [
        "## QWEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIj7Mb1cftI-"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/llm/qwen_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo81tRlREtPA"
      },
      "source": [
        "## DOCOWL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-iPbqE-BKdT"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/docowl_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ys42pTcEzBe"
      },
      "source": [
        "## INTERNVL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnQhZ1SWJuPA"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/llm/internvl_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMyAizd8E3Gr"
      },
      "source": [
        "## OVIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-00XrQVbPzIJ"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/llm/ovis_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGFwbTLME5Fz"
      },
      "source": [
        "## PHI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DxjuGtrUpWR"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/llm/phi_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caIi7kEnE8Gv"
      },
      "source": [
        "## MOLMO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_1-O8XYfeP7"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/llm/molmo_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_boKZV_FDAW"
      },
      "source": [
        "# LM ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TKrrpohFG1Z"
      },
      "source": [
        "## BLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba3YI5H-AAvD"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/lm/blip_evaluator.py --config /VQA_analysis/models/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi8PEKHMFNZN"
      },
      "source": [
        "## UDOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ3b1CDWDDjK"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/lm/udop_evaluator.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iweTGyzFPUr"
      },
      "source": [
        "## LAYOUTLMV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n48jj6LZ4Jkh"
      },
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/lm/layoutLMV3_evaluator.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtyBQ_OVFV98"
      },
      "source": [
        "# ANSWER CONVERSION AND AUGMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardize LLMs output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvgEbW6hAwQ0",
        "outputId": "41666f29-3069-4071-e4ed-3fff6c29afb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini model initialized successfully\n",
            "Processing: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/original/Qwen_vqa_analysis_results.json\n",
            "Saving to: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n",
            "Processed file saved to /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n",
            "Successfully processed: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/original/Qwen_vqa_analysis_results.json\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739471691.324773   59935 init.cc:232] grpc_wait_for_shutdown_with_timeout() timed out.\n"
          ]
        }
      ],
      "source": [
        "!python /VQA_analysis/models/results/MPDocVQA/LLM/unable_converter.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardize LMs output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python /VQA_analysis/models/results/MPDocVQA/LM/unable_converter_binary.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "876GnFNtF-sn"
      },
      "source": [
        "Preprocess metrics files adding "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing metrics file by adding patch_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3LsjjiU1SH",
        "outputId": "847794de-7dc9-4be5-e489-9d093409ea2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini model initialized successfully\n",
            "Processing: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n",
            "Saving to: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/augmented/Qwen_vqa_analysis_results_converted_augmented.json\n",
            "Processed file saved to /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/augmented/Qwen_vqa_analysis_results_converted_augmented.json\n",
            "Successfully processed: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n"
          ]
        }
      ],
      "source": [
        "!python /VQA_analysis/models/results/metrics_file_preprocessing.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrHQKWi2WKRj"
      },
      "source": [
        "Save the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg5PPveSvRMx",
        "outputId": "63fdecd2-5ba9-484b-bfa1-5f947bb2f3ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-13 18:43:38.255153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739472218.288382   62260 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739472218.298555   62260 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-13 18:43:38.329159: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Initializing Entity Verifier...\n",
            "Fetching 5 files: 100% 5/5 [00:00<00:00, 6828.89it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Entity Verifier initialized\n",
            "Base path: /content/drive/MyDrive/Thesis/VQA_analysis/models/results\n",
            "\n",
            "####################################################################################################\n",
            "Processing folder /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name: Qwen\n",
            "Processing /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/augmented/Qwen_vqa_analysis_results_converted_augmented.json\n",
            "Found 1 questions\n",
            "CEPAR - ALL\n",
            "OPAR + ANSL\n",
            "QUR\n",
            "UR\n",
            "AEMR + ALMR + HR\n",
            "QEWR\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "QEPR\n",
            "Metrics\n",
            "Processing CEPAR\n",
            "Processing OPAR_ANSL\n",
            "Processing QUR\n",
            "Processing UR\n",
            "Processing AEMR_ALMR_HR\n",
            "Processing QEWR\n",
            "Processing QEPR\n",
            "Saving files\n",
            "Processed models: ['Qwen']\n"
          ]
        }
      ],
      "source": [
        "!python /VQA_analysis/models/results/result_analysis.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DPC2Cr1WBGjX"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
